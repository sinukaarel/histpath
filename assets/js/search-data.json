{
  
    
        "post0": {
            "title": "Cell detection and classification",
            "content": "Cell detection and classification . Task . Physicians can identify men’s infertility by counting specific cells in testis histopathology images. Such annotation is hard manual labor that can be automated using neural networks. Ida-Tallinn hospital provided a large dataset of these images to build a cell detector and classifier to ease specialists’ lives. . WSI and MIRAX format . Training images WSI (whole slide image) come in MIRAX format - a special kind of virtual slide format. Virtual slide is a high-resolution digital image of the microscopy sample that is created by sliding the glass past the camera and taking multiple pictures. . These created images are too high-resolution to practically handle as image tiles and are broken up into multiple files. This kind of processing needs special notation and a system in order to view and access data after storage. . On disk the format includes: . .mrxs file that holds the metadata including information on how .dat files are organized | data folder with .dat files that hold the actual image data | Index.dat file in data folder that holds the pointers to locate the image data | .json annotation file in JSON format that holds the metadata for the annotated section of the image | Slidedat.ini file in data folder that contains structural data and parameters of the scanning process in key=value format. These values are also used in order to receive image data. | . Example of a single slide . This is a an example of a single training slide. The WSI image has 10 different levels with each level becoming less detailed as the level grows. In this case LVL 10 is the top most layer and the one that has the smallest dimensions and can be used only for thumbnail. The LVL 1 is the lowest layer and has highest dimensions and is most precise. Another factor to consider is that actually most of the image is empty, only proportion of it is actual tissue as can be seen from the LVL 10 image. . . Training dataset . Training dataset consist of 4 WSI slides and each slide has 200 annotations. These annotated cells are different stages of spermatozoid life cycle and based of their proportions, one can diagnose infertility. . Spermatozoid type Annotated cell count . Spermatogonia | 181 | . Primary spermatocyte | 180 | . Spermatid | 180 | . Sertoli | 179 | . Spermatozoa | 80 | . Downscaling images . As the whole-slide images are too big to process it is required to downscale the whole image into smaller tiles. This required to scan the slide with user selected tile size and then collect annotation data if any existed for that tile. Annotated cell center point was used to determine if the cell is on the tile or not. Tiles images were saved and a annotations for the images were saved in COCO format for easier processing. COCO format is something that could be used as an input for different models and frameworks and makes model/framework changing a lot easier if required. . FiftyOne dataset visualization . To get a better overview of the annotation correctness and insights of the data FiftyOne was used. This is a great solution for dataset and model predictions visualization and finding mistakes in annotated images. Good overview of training dataset and prediction visualization help to understand insights of trained model much better. Some of the training images had many annotations, but there were images where only a singe annotated cell was visible. . . Training detection model . After solving the downscaling problem and generating a dataset that can be trained upon it is time to move on to selecting a machine learning framework and a model to train. There are multiple options here to go with, initially Center-Net, was the model in mind, but due to implementation difficulties Pytorch and Faster R-CNN architecture was used. . Custom data loader . In order to pass generated dataset to the Pytorch model a custom data loader needs to be implemented. Unfortunately there is a great tutorial how to implement the data loader for a custom COCO dataset. Also the Pytorch has a good boilerplate for detection training scripts that can be found in their github repo. Combining these two great sources allowed to write the training script more easily. . Augmentations . Detection task needs a little more work than classification task when it comes to image augmentation as the original bounding boxes on images also need to shift and follow the augmented image corresponding sections, so that they also match the cell after augmentation. As the annotation was considered on the image if the annotation center point was on the selected tile, then the bounding boxes shape also need to be limited by the border of the image. . . In order for the model to generalize and achieve better performance image augmentations were used in training process. Albumentations library was used in order to distort the original images. Image normalization values (channels mean and std) were calculated for training and test set and used during training. Also RandomBrightnessContrast and HueSaturationValue transforms were used with default parameters. . . Training . Model was trained on the Tartu University HPC (High Performance Computing Center) using NVIDIA Tesla V100 GPU. . Validation . Non-Max Suppression . Non-Max Suppression is a technique to filter the predictions of object detections. The idea of the Non-Max Suppression is to keep the highest scoring bounding box for a single detection. The IOU (intersection over union) of two bounding boxes is calculated to determine the boxes that overlap and lowest scoring boxes are dropped. This can reduce the predictions noise quite a lot as can be seen in the following image. . . TODO: Mainly, I have to improve model performance. Current issues: - model detects cells very well but can&#39;t distinguish between different types - augmentations maybe too heavy - try to use also lvl 2, 3, 4, 5 images for training . Conclusion . There is lot of work before training the neural network model. Data comes in all sorts of different formats and the preprocessing takes most of the time. Also the job isn’t finished when you have reached the model training phase, there is always room for improvement. Otherwise, lots of new knowledge with WSI, Pytorch, Python, FastPages, using HPC Cluster etc. . Source Code available in: GitHub . Some Good Resources: . Downscaling whole-slide images in Python link | Use tiling and generate smaller images where the sample occupying atleast 90% of the area link | Deephistopath link | .",
            "url": "https://sinukaarel.github.io/histpath/histopathology/2020/01/21/histpath.html",
            "relUrl": "/histopathology/2020/01/21/histpath.html",
            "date": " • Jan 21, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sinukaarel.github.io/histpath/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sinukaarel.github.io/histpath/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}